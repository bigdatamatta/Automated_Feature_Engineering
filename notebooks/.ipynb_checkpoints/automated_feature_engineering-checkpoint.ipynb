{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will automate feature engineering process using library [featuretools](https://www.featuretools.com/)   \n",
    "\n",
    "###  What is feature engineering?\n",
    "\n",
    "It can simply be defined as the process of creating new features from the existing features in a dataset. \n",
    "This is one of critical element in solving data science problem, it's requires domain knowledge and substantial amount of time.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = pd.read_csv('../data/application_train.csv')\n",
    "app_test = pd.read_csv('../data/application_test.csv')\n",
    "bureau = pd.read_csv('../data/bureau.csv')\n",
    "bureau_balance = pd.read_csv('../data/bureau_balance.csv')\n",
    "cash = pd.read_csv('../data/POS_CASH_balance.csv')\n",
    "credit = pd.read_csv('../data/credit_card_balance.csv')\n",
    "previous = pd.read_csv('../data/previous_application.csv')\n",
    "installments = pd.read_csv('../data/installments_payments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scheme of tables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/home_credit_data.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add name to dataframe\n",
    "app_train.name = 'app_train'\n",
    "app_test.name = 'app_test'\n",
    "bureau.name = 'bureau'\n",
    "bureau_balance.name = 'bureau_balance'\n",
    "cash.name = 'cash'\n",
    "credit.name = 'credit'\n",
    "previous.name = 'previous'\n",
    "installments.name = 'installments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_train\t - \t307511 rows\n",
      "app_test\t - \t48744 rows\n",
      "bureau\t - \t1716428 rows\n",
      "bureau_balance\t - \t27299925 rows\n",
      "cash\t - \t10001358 rows\n",
      "credit\t - \t3840312 rows\n",
      "previous\t - \t1670214 rows\n",
      "installments\t - \t13605401 rows\n"
     ]
    }
   ],
   "source": [
    "# Numbers of rows for each table in dataset:\n",
    "datasets_list = [app_train, app_test, bureau, bureau_balance, cash, credit, previous, installments]\n",
    "\n",
    "\n",
    "for ds in datasets_list:\n",
    "    print('{}\\t - \\t{} rows'.format(ds.name , ds.iloc[:, 0].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the anomalous values\n",
    "for ds in datasets_list:\n",
    "    ds.replace({365243: np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I join train and test set to make sure, that the same feature are created for each set. Later it will be separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test['TARGET'] = np.nan\n",
    "app = app_train.append(app_test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Featuretools library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define `EntitySet`. In [docs](https://docs.featuretools.com/loading_data/using_entitysets.html)  EntitySet is defined as a collection of entities and the relationships between them. They are useful for preparing raw, structured datasets for feature engineering.\n",
    "\n",
    "EntitySet keep track of all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet(id = 'clients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicitly define some feature types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools.variable_types as vtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_types = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean variables\n",
    "for col in app.columns:\n",
    "    if (app[col].nunique() == 2) and (app[col].dtype == float):\n",
    "        app_types[col] = vtypes.Boolean\n",
    "        \n",
    "del app_types['TARGET']\n",
    "\n",
    "\n",
    "# Ordinal variables\n",
    "app_types['REGION_RATING_CLIENT'] = vtypes.Ordinal\n",
    "app_types['REGION_RATING_CLIENT_W_CITY'] = vtypes.Ordinal\n",
    "app_types['HOUR_APPR_PROCESS_START'] = vtypes.Ordinal\n",
    "\n",
    "previous_types = {}\n",
    "\n",
    "for col in previous.columns:\n",
    "    if ( previous[col].nunique() == 2) and (previous[col].dtype == float):\n",
    "        previous_types[col] = vtypes.Boolean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop `SK_ID_CURR` in `installments`, `credit`, `cash` because I will link to these dataset through `previous` and `SK_ID_PREV`. See tables scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments = installments.drop(columns = ['SK_ID_CURR'])\n",
    "credit = credit.drop(columns = ['SK_ID_CURR'])\n",
    "cash = cash.drop(columns = ['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Entities to EntitySet. An Entity can be considered as a representation of a Pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.entity_from_dataframe(entity_id = 'app', dataframe = app, index = 'SK_ID_CURR', variable_types=app_types)\n",
    "es = es.entity_from_dataframe(entity_id = 'bureau', dataframe = bureau, index = 'SK_ID_BUREAU')\n",
    "es = es.entity_from_dataframe(entity_id = 'previous', dataframe = previous, index = 'SK_ID_PREV', variable_types= previous_types )\n",
    "\n",
    "# Entities without unique index. We need to add.\n",
    "es = es.entity_from_dataframe(entity_id = 'bureau_balance', dataframe = bureau_balance, \n",
    "                             make_index = True, index = 'bureaubalance_index')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'cash', dataframe = cash, \n",
    "                             make_index = True, index = 'cash_index')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'installments', dataframe = installments,\n",
    "                             make_index = True, index = 'installments_index')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'credit', dataframe = credit,\n",
    "                             make_index = True, index = 'credit_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define relationship between tables using indicies. This it to tell featuretool, how tables are related and how they can be joined. This is requires from us specific knowledge about this particular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_app_bureau = ft.Relationship(es['app']['SK_ID_CURR'], es['bureau']['SK_ID_CURR'])\n",
    "r_bureau_balance = ft.Relationship(es['bureau']['SK_ID_BUREAU'], es['bureau_balance']['SK_ID_BUREAU'])\n",
    "r_app_previous = ft.Relationship(es['app']['SK_ID_CURR'], es['previous']['SK_ID_CURR'])\n",
    "r_previous_cash = ft.Relationship(es['previous']['SK_ID_PREV'], es['cash']['SK_ID_PREV'])\n",
    "r_previous_installments = ft.Relationship(es['previous']['SK_ID_PREV'], es['installments']['SK_ID_PREV'])\n",
    "r_previous_credit = ft.Relationship(es['previous']['SK_ID_PREV'], es['credit']['SK_ID_PREV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add relationships to EntitySet\n",
    "es = es.add_relationships([r_app_bureau, r_bureau_balance,  r_app_previous, r_previous_cash, r_previous_installments, r_previous_credit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to define `feature primitives`. Feature primitives are the building blocks of Featuretools. They define individual computations that can be applied to raw datasets to create new features. See [docs.](https://docs.featuretools.com/automated_feature_engineering/primitives.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primitives = ft.list_primitives()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primitives.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define default premitives\n",
    "agg_primitives = [\"sum\", \"max\", \"min\", \"mean\", \"count\", \"percent_true\", \"num_unique\", \"mode\"]\n",
    "trans_primitives = ['percentile', 'and']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Featuretools uses **Deep Feature Synthesis** to generate new features. More information about DFS [here](https://www.featurelabs.com/blog/deep-feature-synthesis/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep feature synthesis\n",
    "feature_names = ft.dfs(entityset = es, target_entity = 'app', \n",
    "                        trans_primitives = trans_primitives,\n",
    "                        agg_primitives = agg_primitives, \n",
    "                        max_depth = 2, n_jobs = 1, verbose = 1,\n",
    "                        features_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `features_only` true, only feature names are created and actual values of the features are not computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.save_features(feature_names, '../input/features2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Due to constrains of my local machine, above code to was ran on AWS EC2. DFS generated  1800 features names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
