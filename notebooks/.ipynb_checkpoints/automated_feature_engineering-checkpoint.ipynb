{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will automate feature engineering process using library [featuretools](https://www.featuretools.com/)   \n",
    "\n",
    "###  What is feature engineering?\n",
    "\n",
    "It can simply be defined as the process of creating new features from the existing features in a dataset. \n",
    "This is one of critical element in solving data science problem, it's requires domain knowledge and substantial amount of time.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Featuretools basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Featuretools** is an open-source Python library for automatically creating features out of a set of related tables using a technique called **Deep Feature Synthesis**. Automated feature engineering, like many topics in machine learning, is a complex subject built upon a foundation of simpler ideas. By going through these ideas one at a time, we can build up our understanding of Featuretools which will later allow for us to get the most out of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming up with features is difficult, time-consuming, and requires expert knowledge. ‘Applied machine learning’ is basically feature engineering.\n",
    "\n",
    "— Andrew Ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle competition **The Home Credit Default Risk** is a supervised classification task where the objective is to predict whether or not an applicant for a loan (known as a client) will default on the loan. The data comprises socio-economic indicators for the clients, loan specific financial information, and comprehensive data on previous loans at Home Credit (the institution sponsoring the competition) and other credit agencies. The metric for this competition is Receiver Operating Characteristic Area Under the Curve (ROC AUC) with predictions made in terms of the probability of default. We can evaluate our submissions both through cross-validation on the training data (for which we have the labels) or by submitting our test predictions to Kaggle to see where we place on the public leaderboard (which is calculated with only 10% of the testing data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = pd.read_csv('../data/application_train.csv')\n",
    "app_test = pd.read_csv('../data/application_test.csv')\n",
    "bureau = pd.read_csv('../data/bureau.csv')\n",
    "bureau_balance = pd.read_csv('../data/bureau_balance.csv')\n",
    "cash = pd.read_csv('../data/POS_CASH_balance.csv')\n",
    "credit = pd.read_csv('../data/credit_card_balance.csv')\n",
    "previous = pd.read_csv('../data/previous_application.csv')\n",
    "installments = pd.read_csv('../data/installments_payments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scheme of tables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/home_credit_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables that tie the tables together will be important to understand when it comes to adding relationships between entities. **The only domain knowledge we need for a full Featuretools approach to the problem is the indexes of the tables and the relationships between the tables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# Add name to dataframe\n",
    "app_train.name = 'app_train'\n",
    "app_test.name = 'app_test'\n",
    "bureau.name = 'bureau'\n",
    "bureau_balance.name = 'bureau_balance'\n",
    "cash.name = 'cash'\n",
    "credit.name = 'credit'\n",
    "previous.name = 'previous'\n",
    "installments.name = 'installments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_train\t - \t307511 rows\n",
      "app_test\t - \t48744 rows\n",
      "bureau\t - \t1716428 rows\n",
      "bureau_balance\t - \t27299925 rows\n",
      "cash\t - \t10001358 rows\n",
      "credit\t - \t3840312 rows\n",
      "previous\t - \t1670214 rows\n",
      "installments\t - \t13605401 rows\n"
     ]
    }
   ],
   "source": [
    "# Numbers of rows for each table in dataset:\n",
    "datasets_list = [app_train, app_test, bureau, bureau_balance, cash, credit, previous, installments]\n",
    "\n",
    "\n",
    "for ds in datasets_list:\n",
    "    print('{}\\t - \\t{} rows'.format(ds.name , ds.iloc[:, 0].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "# replace the anomalous values\n",
    "for ds in datasets_list:\n",
    "    ds.replace({365243: np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I join train and test set to make sure, that the same feature are created for each set. Later it will be separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "app_test['TARGET'] = np.nan\n",
    "app = app_train.append(app_test, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Featuretools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few concepts that we will cover along the way:\n",
    "\n",
    "- **Entities and EntitySets**: our tables and a data structure for keeping track of them all\n",
    "- **Relationships between tables**: how the tables can be related to one another\n",
    "- **Feature primitives**: aggregations and transformations that are stacked to build features\n",
    "- **Deep feature synthesis**: the method that uses feature primitives to generate thousands of new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EntitySet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define `EntitySet`. In [docs](https://docs.featuretools.com/loading_data/using_entitysets.html)  EntitySet is defined as a collection of entities and the relationships between them. They are useful for preparing raw, structured datasets for feature engineering.\n",
    "\n",
    "EntitySet keep track of all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet(id = 'clients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicitly define some feature types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools.variable_types as vtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_types = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean variables\n",
    "for col in app.columns:\n",
    "    if (app[col].nunique() == 2) and (app[col].dtype == float):\n",
    "        app_types[col] = vtypes.Boolean\n",
    "        \n",
    "del app_types['TARGET']\n",
    "\n",
    "\n",
    "# Ordinal variables\n",
    "app_types['REGION_RATING_CLIENT'] = vtypes.Ordinal\n",
    "app_types['REGION_RATING_CLIENT_W_CITY'] = vtypes.Ordinal\n",
    "app_types['HOUR_APPR_PROCESS_START'] = vtypes.Ordinal\n",
    "\n",
    "previous_types = {}\n",
    "\n",
    "for col in previous.columns:\n",
    "    if ( previous[col].nunique() == 2) and (previous[col].dtype == float):\n",
    "        previous_types[col] = vtypes.Boolean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop `SK_ID_CURR` in `installments`, `credit`, `cash` because I will link to these dataset through `previous` and `SK_ID_PREV`. See tables scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "bureau['SK_ID_BUREAU'] = bureau['SK_ID_BUREAU'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "previous['SK_ID_PREV'] = previous['SK_ID_PREV'].astype(np.int64)\n",
    "cash['SK_ID_PREV'] = cash['SK_ID_PREV'].astype(np.int64)\n",
    "installments['SK_ID_PREV'] = installments['SK_ID_PREV'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments = installments.drop(columns = ['SK_ID_CURR'])\n",
    "credit = credit.drop(columns = ['SK_ID_CURR'])\n",
    "cash = cash.drop(columns = ['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Entities to EntitySet. An Entity can be considered as a representation of a Pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.entity_from_dataframe(entity_id = 'app', dataframe = app, index = 'SK_ID_CURR', variable_types=app_types)\n",
    "es = es.entity_from_dataframe(entity_id = 'bureau', dataframe = bureau, index = 'SK_ID_BUREAU')\n",
    "es = es.entity_from_dataframe(entity_id = 'previous', dataframe = previous, index = 'SK_ID_PREV', variable_types= previous_types )\n",
    "\n",
    "# Entities without unique index. We need to add.\n",
    "es = es.entity_from_dataframe(entity_id = 'bureau_balance', dataframe = bureau_balance, \n",
    "                             make_index = True, index = 'bureaubalance_index')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'cash', dataframe = cash, \n",
    "                             make_index = True, index = 'cash_index')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'installments', dataframe = installments,\n",
    "                             make_index = True, index = 'installments_index')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'credit', dataframe = credit,\n",
    "                             make_index = True, index = 'credit_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define relationship between tables using indicies. This it to tell featuretool, how tables are related and how they can be joined. This is requires from us specific knowledge about this particular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_app_bureau = ft.Relationship(es['app']['SK_ID_CURR'], es['bureau']['SK_ID_CURR'])\n",
    "r_bureau_balance = ft.Relationship(es['bureau']['SK_ID_BUREAU'], es['bureau_balance']['SK_ID_BUREAU'])\n",
    "r_app_previous = ft.Relationship(es['app']['SK_ID_CURR'], es['previous']['SK_ID_CURR'])\n",
    "r_previous_cash = ft.Relationship(es['previous']['SK_ID_PREV'], es['cash']['SK_ID_PREV'])\n",
    "r_previous_installments = ft.Relationship(es['previous']['SK_ID_PREV'], es['installments']['SK_ID_PREV'])\n",
    "r_previous_credit = ft.Relationship(es['previous']['SK_ID_PREV'], es['credit']['SK_ID_PREV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add relationships to EntitySet\n",
    "es = es.add_relationships([r_app_bureau, r_bureau_balance,  r_app_previous, r_previous_cash, r_previous_installments, r_previous_credit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: clients\n",
       "  Entities:\n",
       "    app [Rows: 356255, Columns: 122]\n",
       "    bureau [Rows: 1716428, Columns: 17]\n",
       "    previous [Rows: 1670214, Columns: 37]\n",
       "    bureau_balance [Rows: 27299925, Columns: 4]\n",
       "    cash [Rows: 10001358, Columns: 8]\n",
       "    installments [Rows: 13605401, Columns: 8]\n",
       "    credit [Rows: 3840312, Columns: 23]\n",
       "  Relationships:\n",
       "    bureau.SK_ID_CURR -> app.SK_ID_CURR\n",
       "    bureau_balance.SK_ID_BUREAU -> bureau.SK_ID_BUREAU\n",
       "    previous.SK_ID_CURR -> app.SK_ID_CURR\n",
       "    cash.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    installments.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    credit.SK_ID_PREV -> previous.SK_ID_PREV"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Primitives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **feature primitive** is an operation applied to a table or a set of tables to create a feature. These represent simple calculations, many of which we already use in manual feature engineering, that can be stacked on top of each other to create complex deep features. Feature primitives fall into two categories:\n",
    "\n",
    "`Aggregation`: function that groups together children for each parent and calculates a statistic such as mean, min, max, or standard deviation across the children. An example is the maximum previous loan amount for each client. An aggregation covers multiple tables using relationships between tables.\n",
    "`Transformation`: an operation applied to one or more columns in a single table. An example would be taking the absolute value of a column, or finding the difference between two columns in one table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to define `feature primitives`. Feature primitives are the building blocks of Featuretools. They define individual computations that can be applied to raw datasets to create new features. See [docs.](https://docs.featuretools.com/automated_feature_engineering/primitives.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "primitives = ft.list_primitives()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the maximum non-null value of a numeric feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avg_time_between</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the average time between consecutive events.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mean</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the average value of a numeric feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>num_unique</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Returns the number of unique categorical variables.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>any</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Test if any value is 'True'.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n_most_common</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the N most common elements in a categorical feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>std</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the standard deviation of a numeric feature ignoring null values.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>skew</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Computes the skewness of a data set.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>count</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Counts the number of non null values.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>all</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Test if all values are 'True'.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>percent_true</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the percent of 'True' values in a boolean feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>min</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the minimum non-null value of a numeric feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>last</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Returns the last value.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>num_true</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the number of 'True' values in a boolean.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>trend</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Calculates the slope of the linear trend of variable overtime.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>median</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the median value of any feature with well-ordered values.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>time_since_last</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Time since last related instance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mode</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Finds the most common element in a categorical feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sum</td>\n",
       "      <td>aggregation</td>\n",
       "      <td>Sums elements of a numeric or boolean feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>days</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number of days.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>seconds</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number of seconds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>and</td>\n",
       "      <td>transform</td>\n",
       "      <td>For two boolean values, determine if both values are 'True'.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cum_max</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the max of previous values of an instance for each value in a time-dependent entity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>not</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of the base feature, negates the boolean value.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>diff</td>\n",
       "      <td>transform</td>\n",
       "      <td>Compute the difference between the value of a base feature and the previous value.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>second</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the second.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>numwords</td>\n",
       "      <td>transform</td>\n",
       "      <td>Returns the words in a given string by counting the spaces.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>multiply</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that multplies two features.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>latitude</td>\n",
       "      <td>transform</td>\n",
       "      <td>Returns the first value of the tuple base feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>weekend</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform Datetime feature into the boolean of Weekend.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>years</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number of years.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mod</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that divides two features.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>hours</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number of hours.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>haversine</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculate the approximate haversine distance in miles between two LatLong variable types.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>characters</td>\n",
       "      <td>transform</td>\n",
       "      <td>Return the characters in a given string.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>add</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that adds two features.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>week</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the week.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>percentile</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of the base feature, determines the percentile in relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>absolute</td>\n",
       "      <td>transform</td>\n",
       "      <td>Absolute value of base feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>cum_mean</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the mean of previous values of an instance for each value in a time-dependent entity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>divide</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that divides two features.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>time_since</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates time since the cutoff time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>minutes</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number of minutes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>isin</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of the base feature, checks whether it is in a provided list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>minute</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the minute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>hour</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the hour.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>is_null</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of base feature, return 'True' if value is null.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>month</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the month.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>weekday</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform Datetime feature into the boolean of Weekday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>cum_min</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the min of previous values of an instance for each value in a time-dependent entity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>cum_count</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the number of previous values of an instance for each value in a time-dependent entity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>negate</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that negates a feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>months</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Timedelta feature into the number of months.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>day</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>days_since</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of the base feature, compute the number of days between it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>subtract</td>\n",
       "      <td>transform</td>\n",
       "      <td>Creates a transform feature that subtracts two features.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>year</td>\n",
       "      <td>transform</td>\n",
       "      <td>Transform a Datetime feature into the year.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>longitude</td>\n",
       "      <td>transform</td>\n",
       "      <td>Returns the second value on the tuple base feature.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>cum_sum</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the sum of previous values of an instance for each value in a time-dependent entity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>time_since_previous</td>\n",
       "      <td>transform</td>\n",
       "      <td>Compute the time since the previous instance.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name         type                                                                                         description\n",
       "0                   max  aggregation                                              Finds the maximum non-null value of a numeric feature.\n",
       "1      avg_time_between  aggregation                                               Computes the average time between consecutive events.\n",
       "2                  mean  aggregation                                                    Computes the average value of a numeric feature.\n",
       "3            num_unique  aggregation                                                 Returns the number of unique categorical variables.\n",
       "4                   any  aggregation                                                                        Test if any value is 'True'.\n",
       "5         n_most_common  aggregation                                          Finds the N most common elements in a categorical feature.\n",
       "6                   std  aggregation                             Finds the standard deviation of a numeric feature ignoring null values.\n",
       "7                  skew  aggregation                                                                Computes the skewness of a data set.\n",
       "8                 count  aggregation                                                               Counts the number of non null values.\n",
       "9                   all  aggregation                                                                      Test if all values are 'True'.\n",
       "10         percent_true  aggregation                                            Finds the percent of 'True' values in a boolean feature.\n",
       "11                  min  aggregation                                              Finds the minimum non-null value of a numeric feature.\n",
       "12                 last  aggregation                                                                             Returns the last value.\n",
       "13             num_true  aggregation                                                     Finds the number of 'True' values in a boolean.\n",
       "14                trend  aggregation                                      Calculates the slope of the linear trend of variable overtime.\n",
       "15               median  aggregation                                     Finds the median value of any feature with well-ordered values.\n",
       "16      time_since_last  aggregation                                                                   Time since last related instance.\n",
       "17                 mode  aggregation                                             Finds the most common element in a categorical feature.\n",
       "18                  sum  aggregation                                                      Sums elements of a numeric or boolean feature.\n",
       "19                 days    transform                                              Transform a Timedelta feature into the number of days.\n",
       "20              seconds    transform                                           Transform a Timedelta feature into the number of seconds.\n",
       "21                  and    transform                                        For two boolean values, determine if both values are 'True'.\n",
       "22              cum_max    transform     Calculates the max of previous values of an instance for each value in a time-dependent entity.\n",
       "23                  not    transform                                      For each value of the base feature, negates the boolean value.\n",
       "24                 diff    transform                  Compute the difference between the value of a base feature and the previous value.\n",
       "25               second    transform                                                       Transform a Datetime feature into the second.\n",
       "26             numwords    transform                                         Returns the words in a given string by counting the spaces.\n",
       "27             multiply    transform                                            Creates a transform feature that multplies two features.\n",
       "28             latitude    transform                                                  Returns the first value of the tuple base feature.\n",
       "29              weekend    transform                                             Transform Datetime feature into the boolean of Weekend.\n",
       "..                  ...          ...                                                                                                 ...\n",
       "32                years    transform                                             Transform a Timedelta feature into the number of years.\n",
       "33                  mod    transform                                              Creates a transform feature that divides two features.\n",
       "34                hours    transform                                             Transform a Timedelta feature into the number of hours.\n",
       "35            haversine    transform           Calculate the approximate haversine distance in miles between two LatLong variable types.\n",
       "36           characters    transform                                                            Return the characters in a given string.\n",
       "37                  add    transform                                                 Creates a transform feature that adds two features.\n",
       "38                 week    transform                                                         Transform a Datetime feature into the week.\n",
       "39           percentile    transform                           For each value of the base feature, determines the percentile in relation\n",
       "40             absolute    transform                                                                     Absolute value of base feature.\n",
       "41             cum_mean    transform    Calculates the mean of previous values of an instance for each value in a time-dependent entity.\n",
       "42               divide    transform                                              Creates a transform feature that divides two features.\n",
       "43           time_since    transform                                                              Calculates time since the cutoff time.\n",
       "44              minutes    transform                                           Transform a Timedelta feature into the number of minutes.\n",
       "45                 isin    transform                        For each value of the base feature, checks whether it is in a provided list.\n",
       "46               minute    transform                                                       Transform a Datetime feature into the minute.\n",
       "47                 hour    transform                                                         Transform a Datetime feature into the hour.\n",
       "48              is_null    transform                                     For each value of base feature, return 'True' if value is null.\n",
       "49                month    transform                                                        Transform a Datetime feature into the month.\n",
       "50              weekday    transform                                             Transform Datetime feature into the boolean of Weekday.\n",
       "51              cum_min    transform     Calculates the min of previous values of an instance for each value in a time-dependent entity.\n",
       "52            cum_count    transform  Calculates the number of previous values of an instance for each value in a time-dependent entity.\n",
       "53               negate    transform                                                 Creates a transform feature that negates a feature.\n",
       "54               months    transform                                            Transform a Timedelta feature into the number of months.\n",
       "55                  day    transform                                                          Transform a Datetime feature into the day.\n",
       "56           days_since    transform                           For each value of the base feature, compute the number of days between it\n",
       "57             subtract    transform                                            Creates a transform feature that subtracts two features.\n",
       "58                 year    transform                                                         Transform a Datetime feature into the year.\n",
       "59            longitude    transform                                                 Returns the second value on the tuple base feature.\n",
       "60              cum_sum    transform     Calculates the sum of previous values of an instance for each value in a time-dependent entity.\n",
       "61  time_since_previous    transform                                                       Compute the time since the previous instance.\n",
       "\n",
       "[62 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>percentile</td>\n",
       "      <td>transform</td>\n",
       "      <td>For each value of the base feature, determines the percentile in relation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name       type                                                                description\n",
       "39  percentile  transform  For each value of the base feature, determines the percentile in relation"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primitives[primitives['name'] =='percentile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define default premitives\n",
    "agg_primitives = [\"sum\", \"max\", \"min\", \"mean\", \"count\", \"percent_true\", \"num_unique\", \"mode\"]\n",
    "trans_primitives = ['percentile', 'and', 'diff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep feature synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep Feature Synthesis** (DFS) is the method Featuretools uses to make new features. DFS stacks feature primitives to form features with a \"depth\" equal to the number of primitives. For example, if we take the maximum value of a client's previous loans (say MAX(previous.loan_amount)), that is a \"deep feature\" with a depth of 1. To create a feature with a depth of two, we could stack primitives by taking the maximum value of a client's average monthly payments per previous loan (such as MAX(previous(MEAN(installments.payment)))). In manual feature engineering, this would require two separate groupings and aggregations and took more than 15 minutes to write the code per feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Featuretools uses **Deep Feature Synthesis** to generate new features. More information about DFS [here](https://www.featurelabs.com/blog/deep-feature-synthesis/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 5152 features\n"
     ]
    }
   ],
   "source": [
    "# Deep feature synthesis\n",
    "feature_names = ft.dfs(entityset = es, target_entity = 'app', \n",
    "                        trans_primitives = trans_primitives,\n",
    "                        agg_primitives = agg_primitives, \n",
    "                        max_depth = 3, n_jobs = 1, verbose = 1,\n",
    "                        features_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `features_only` true, only feature names are created and actual values of the features are not computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Feature: MEAN(previous.PERCENTILE(SUM(credit.AMT_PAYMENT_CURRENT)))>,\n",
       " <Feature: MEAN(previous.PERCENTILE(SUM(credit.AMT_PAYMENT_TOTAL_CURRENT)))>,\n",
       " <Feature: MEAN(previous.PERCENTILE(SUM(credit.AMT_RECEIVABLE_PRINCIPAL)))>,\n",
       " <Feature: MEAN(previous.PERCENTILE(SUM(credit.AMT_RECIVABLE)))>,\n",
       " <Feature: MEAN(previous.PERCENTILE(SUM(credit.AMT_TOTAL_RECEIVABLE)))>,\n",
       " <Feature: MEAN(previous.PERCENTILE(SUM(credit.CNT_DRAWINGS_ATM_CURRENT)))>,\n",
       " <Feature: MEAN(previous.PERCENTILE(SUM(credit.CNT_DRAWINGS_CURRENT)))>,\n",
       " <Feature: MEAN(previous.PERCENTILE(SUM(credit.CNT_DRAWINGS_OTHER_CURRENT)))>,\n",
       " <Feature: MEAN(previous.PERCENTILE(SUM(credit.CNT_DRAWINGS_POS_CURRENT)))>,\n",
       " <Feature: MEAN(previous.PERCENTILE(SUM(credit.CNT_INSTALMENT_MATURE_CUM)))>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.save_features(feature_names, '../input/features_names_depth3_5152.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Due to constrains of my local machine, above code to was ran on AWS EC2. DFS generated  1800 features names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "591px",
    "left": "1338.67px",
    "right": "20px",
    "top": "122px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
